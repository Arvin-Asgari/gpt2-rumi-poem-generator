# GPT-2 Rumi Poem Generator ğŸª¶âœ¨

**Fine-tuned Persian GPT-2 on 6000+ lines of Rumi poetry** to generate creative poems from any input prompt.

## ğŸ“‹ Features
- Fine-tuned `HooshvareLab/gpt2-fa` on extensive Rumi poetry dataset
- Interactive poem generation with advanced sampling (top-k=50, top-p=0.95)
- Temperature-controlled creativity (0.7 default)
- Generates multiple poem variations per prompt

## ğŸ› ï¸ Tech Stack
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C?style=flat&logo=PyTorch&logoColor=white)
![HuggingFace](https://img.shields.io/badge/HuggingFace-%23FFD21E?style=flat&logo=huggingface&logoColor=black)

## ğŸš€ Quick Start

**1. Install Dependencies**
```bash
pip install torch transformers datasets accelerate
```

**2. Train Model**
*(Requires a text file containing Rumi's poetry)*
```bash
python poem_generator.py --train
```

**3. Generate Poems**
```bash
python poem_generator.py --generate "Ø¯Ù„Ø¨Ø±"  # Enter Persian prompt
```

## ğŸ¯ Example Output

```text
Prompt: "Ø¯Ù„Ø¨Ø±"
Output: "Ø¯Ù„Ø¨Ø±Ø§ Ú©Ù‡ Ø¯Ø± Ø®Ù„ÙˆØª Ù…Ù†ÛŒ Ùˆ Ø¯Ø± Ø´Ø§Ø¯ÛŒ Ù…Ù†ÛŒ..."
```

## ğŸ“ Files
```text
â”œâ”€â”€ poem_generator.py      # Fine-tuning + inference pipeline
â””â”€â”€ requirements.txt       # Dependencies
```

## ğŸ“ What I Learned
- **Hugging Face Trainer API** for efficient fine-tuning
- **Advanced text generation parameters** (top-k/p, temperature)
- **Persian NLP model adaptation** and tokenization challenges
